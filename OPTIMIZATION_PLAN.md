# 模型优化方案 (Phase 2)

## 1. 现状回顾与问题分析

### 1.1 当前状态 (Phase 1)
在此前的优化中，我们修复了最致命的工程错误——**解冻了 mT5 Encoder**。这解决了跨模态输入的基本适配问题。
然而，模型目前的训练效果仍然很差（完全匹配率接近 0%），验证集 Loss 居高不下。这表明单纯的参数解冻无法弥补架构上的本质缺失。

### 1.2 核心瓶颈分析
基于手语翻译（SLT）的领域特性，当前架构存在以下核心缺陷：
1.  **语义信息缺失**: 仅使用身体和手部关键点，丢失了面部表情（非手控特征）这一关键语法载体（如疑问、否定、语气）。
2.  **监督信号稀疏**: 仅依靠最终的文本生成 Loss (CrossEntropy) 来训练整个长序列视觉编码器，梯度难以有效反向传播，导致视觉特征塌缩。
3.  **时序建模薄弱**: GCN 仅提取帧内空间特征，线性映射无法捕捉动作的动态演变（如“挥手”是一个过程），且原始帧率（25fps）对于 mT5 来说序列过长且冗余。

---

## 2. 下一阶段架构设计 (Phase 2)

为了解决上述问题，我们将对模型架构进行系统性升级。

### 2.1 总体架构图

```mermaid
graph TD
    A[输入: 全身关键点序列] --> B[数据预处理]
    B --> C[空间特征提取 (GCN)]
    
    subgraph 视觉编码器
    C --> D[时序建模 (Temporal Module)]
    D --> E[视觉-语言对齐 (Visual Adapter)]
    end
    
    D -.-> |辅助监督| F[CTC Loss (Gloss)]
    E --> G[mT5 Encoder (LoRA/Full)]
    G --> H[mT5 Decoder (LoRA/Full)]
    H --> I[输出: 中文文本]
```

### 2.2 详细改进方案

#### 🔴 改进一：数据增强与特征扩充 (Data)
*   **找回面部关键点**: 在 `datasets_lite.py` 中增加面部关键点加载逻辑。
    *   **策略**: 既然已通过 `pose_format` 加载了 133 点，应提取 **眉毛** (情感/语法)、**眼睛** (视线) 和 **口型** (副词)。
    *   **归一化**: 面部关键点位移较小，需以鼻尖为中心进行独立归一化。
*   **数据增强 (Augmentation)**:
    *   **随机旋转**: +/- 15度。
    *   **随机缩放**: 模拟不同拍摄距离。
    *   **时序扰动**: 随机丢帧或插帧，模拟不同打手语速度。

#### 🟠 改进二：辅助监督信号 (Gloss CTC)
*   **引入 Gloss (手语词)**: CSL-Daily 数据集包含 Gloss 标注。
*   **CTC Loss**: 在时序模块后添加一个线性层，预测 Gloss 序列，计算 CTC Loss。
    *   **作用**: 强迫视觉编码器学习到“有意义”的手语语义特征，而不是随机噪声，显著加速收敛。
    *   **公式**: $L_{total} = L_{Translation} + \lambda \cdot L_{CTC}$

#### 🟡 改进三：增强时序建模 (Temporal Modeling)
*   **引入时序层**: 在 GCN 和 mT5 之间插入轻量级时序模块。
    *   **方案 A (推荐)**: **Bi-GRU** (2层, hidden_size=256)。参数少，适合序列建模。
    *   **方案 B**: **1D-CNN / MS-TCN**。适合提取局部时序特征。
*   **下采样 (Downsampling)**: 通过 Stride Conv 或 Pooling 将序列长度缩减 2x 或 4x（例如 128帧 -> 32帧特征）。这能极大减轻 mT5 的计算负担并过滤冗余信息。

#### 🔵 改进四：预训练对齐策略
*   **冷启动对齐**:
    1.  **Stage 1**: 冻结 mT5，只训练前端 (GCN + Temporal + Adapter)。使用 CTC Loss 和 Translation Loss。目的是让视觉特征“适配”mT5 的输入空间。
    2.  **Stage 2**: 解冻 mT5 (建议使用 LoRA)，进行全参数微调。

---

## 3. 实施路线图

### 阶段 1: 数据层升级 (优先级：高)
- [x] 修改 `datasets_lite.py`，增加面部关键点提取逻辑。
- [ ] 实现基础数据增强（随机旋转、缩放）。

### 阶段 2: 引入 CTC 监督 (优先级：最高)
- [x] 修改 `datasets_lite.py`，加载 Gloss 标签并建立词表。
- [x] 修改 `models_lite.py`，在 Visual Encoder 后增加 Gloss Head。
- [x] 修改 `train.py`，引入 `ctc_loss`，并实现混合 Loss 训练。

### 阶段 3: 时序模块增强 (优先级：中)
- [x] 在 `SignLanguageLite` 中加入 `nn.GRU` 模块 (Bi-GRU)。
- [x] 在进入 mT5 前进行时序池化/下采样 (2x)。

### 阶段 4: 进阶训练配置 (优先级：低)
- [ ] 引入 LoRA 降低显存消耗。
- [ ] 编写两阶段训练脚本。

---

## 4. 预期性能提升
通过上述改进，预期模型在验证集上的表现将有如下改善：
*   **收敛稳定性**: Loss 曲线将更加平滑，不再出现 7.0 这样的高 Loss。
*   **完全匹配率**: 逐步提升，突破 0% 的瓶颈。
*   **翻译质量**: 生成的文本将更符合中文语法，语义更准确。
